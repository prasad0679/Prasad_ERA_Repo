{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXExBCHxNBTfvy5ruPDN4E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import sys\n","# Standard Library Imports\n","import math\n","from typing import NoReturn\n","\n","# Third-Party Imports\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from torchsummary import summary\n","from torchvision import transforms"],"metadata":{"id":"bZ0nk-QjVseu","executionInfo":{"status":"ok","timestamp":1692102750141,"user_tz":-330,"elapsed":10477,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#!pip install grad-cam"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ym7qYAv75zfc","executionInfo":{"status":"ok","timestamp":1690638501708,"user_tz":-330,"elapsed":15158,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}},"outputId":"d6b8db08-a0db-471d-ded2-698de61cdb89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting grad-cam\n","  Downloading grad-cam-1.4.8.tar.gz (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.22.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from grad-cam) (9.4.0)\n","Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (0.15.2+cu118)\n","Collecting ttach (from grad-cam)\n","  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.65.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.7.0.72)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from grad-cam) (3.7.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.1->grad-cam) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.1->grad-cam) (16.0.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.2->grad-cam) (2.27.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (2.8.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\n","Building wheels for collected packages: grad-cam\n","  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for grad-cam: filename=grad_cam-1.4.8-py3-none-any.whl size=38247 sha256=442ed2e7cd2db5b2f124c5db1bb81978dc321d5401fdf63f4627060dce753de1\n","  Stored in directory: /root/.cache/pip/wheels/f8/04/36/94ff3c8a4215826a21946b34c01180817e606989fdf53f7cd6\n","Successfully built grad-cam\n","Installing collected packages: ttach, grad-cam\n","Successfully installed grad-cam-1.4.8 ttach-0.0.3\n"]}]},{"cell_type":"code","source":["from pytorch_grad_cam import GradCAM\n","from pytorch_grad_cam.utils.image import show_cam_on_image"],"metadata":{"id":"vT0IZ6FW54c5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.simplefilter(\"ignore\")\n","warnings.warn(\"deprecated\", DeprecationWarning)\n","warnings.filterwarnings( \"ignore\", module = \"matplotlib\\..*\" )"],"metadata":{"id":"uQgcsjkMibZ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"id":"5LCyI6D3bGNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def allot_device(random_seed_value):\n","    if torch.cuda.is_available():\n","        device = \"cuda\"\n","        torch.manual_seed(random_seed_value)\n","    else:\n","        device = \"cpu\"\n","    return device"],"metadata":{"id":"FOpQRk-7a8ZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Plots:\n","    def __init__(self,mis_classify_details=None ,num_images=None, loaded_data=None):\n","        self.num_images = num_images\n","        self.loaded_data = loaded_data\n","        self.mis_classify = mis_classify_details\n","\n","\n","    def plot_images(self):\n","        batch_data, batch_label = next(iter(self.loaded_data))\n","        fig = plt.figure()\n","        if self.num_images % 2 != 0:\n","            self.num_images -= 1\n","        self.num_rows = self.num_images // 4\n","\n","        fig = plt.figure(figsize=(15, 7))\n","        counter = 0\n","        for i in range(self.num_images):\n","            sub = fig.add_subplot(self.num_rows, 4, i + 1)\n","            im2display = (np.squeeze(batch_data[i].permute(2, 1, 0)))\n","            sub.imshow(im2display.cpu().numpy())\n","            sub.set_title(batch_label[i].item())\n","            sub.axis('off')\n","\n","        plt.tight_layout()\n","        plt.axis('off')\n","        plt.show()\n","\n","    def mis_classified_gradcam(self):\n","        model, testloader, device, images_needed = self.mis_classify\n","        storing_images = []\n","        storing_predicted_labels = []\n","        storing_target_labels = []\n","\n","        target_layers = [model.layer4[-1]]\n","\n","        # Construct the CAM object once, and then re-use it on many images:\n","        cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n","        targets = [ClassifierOutputTarget(281)]\n","\n","        if images_needed == None:\n","            images_needed = random.choice([10, 20])\n","        with torch.no_grad():\n","            model.eval()\n","            for data, target in testloader:\n","                data, target = data.to(device), target.to(device)\n","                output = model(data)\n","                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","                for idx in range(len(pred)):\n","                    if pred[idx] != target[idx]:\n","                        # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n","                        grayscale_cam = cam(input_tensor=data[idx], targets=targets)\n","                        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n","                        #storing_images.append(data[idx])\n","                        storing_images.append(visualization)\n","                        storing_predicted_labels.append(pred[idx])\n","                        storing_target_labels.append(target[idx])\n","\n","        fig = plt.figure(figsize=(20, 14))\n","\n","        if images_needed % 2 != 0:\n","            images_needed -= 1  # It becomes even so plotting would be good.\n","\n","        num_rows = 0\n","        plots_per_row = 0\n","        if images_needed <= 10:\n","            num_rows = 5\n","            plots_per_row = images_needed // num_rows\n","        elif 22 > images_needed > 10:\n","            num_rows = 4\n","            plots_per_row = images_needed // num_rows\n","        elif images_needed > 20:\n","            num_rows = 10\n","            plots_per_row = images_needed // num_rows\n","\n","        for i in range(images_needed):\n","            sub = fig.add_subplot(num_rows, plots_per_row, i + 1)\n","            im2display = (np.squeeze(storing_images[i].permute(2, 1, 0)))\n","            sub.imshow(im2display.cpu().numpy())\n","            sub.set_title(\n","                f\"Predicted as: {classes[storing_predicted_labels[i]]} \\n But, Actual is: {classes[storing_target_labels[i]]}\")\n","        plt.tight_layout()\n","        plt.show()\n","\n","    def mis_classified(self):\n","        model, testloader, device, images_needed = self.mis_classify\n","        storing_images = []\n","        storing_predicted_labels = []\n","        storing_target_labels = []\n","        if images_needed == None:\n","            images_needed = random.choice([10, 20])\n","        with torch.no_grad():\n","            model.eval()\n","            for data, target in testloader:\n","                data, target = data.to(device), target.to(device)\n","                output = model(data)\n","                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","                for idx in range(len(pred)):\n","                    if pred[idx] != target[idx]:\n","                        storing_images.append(data[idx])\n","                        storing_predicted_labels.append(pred[idx])\n","                        storing_target_labels.append(target[idx])\n","\n","        fig = plt.figure(figsize=(20, 14))\n","\n","        if images_needed % 2 != 0:\n","            images_needed -= 1  # It becomes even so plotting would be good.\n","\n","        num_rows = 0\n","        plots_per_row = 0\n","        if images_needed <= 10:\n","            num_rows = 5\n","            plots_per_row = images_needed // num_rows\n","        elif 22 > images_needed > 10:\n","            num_rows = 4\n","            plots_per_row = images_needed // num_rows\n","        elif images_needed > 20:\n","            num_rows = 10\n","            plots_per_row = images_needed // num_rows\n","\n","        for i in range(images_needed):\n","            sub = fig.add_subplot(num_rows, plots_per_row, i + 1)\n","            im2display = (np.squeeze(storing_images[i].permute(2, 1, 0)))\n","            sub.imshow(im2display.cpu().numpy())\n","            sub.set_title(\n","                f\"Predicted as: {classes[storing_predicted_labels[i]]} \\n But, Actual is: {classes[storing_target_labels[i]]}\")\n","        plt.tight_layout()\n","        plt.show()"],"metadata":{"id":"Sud7Ucmba_Nz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_metrics(metrics):\n","    if metrics is None:\n","        print(\"Please provide the metric values, unable to view them!\")\n","        sys.exit(0)\n","    else:\n","        train_losses, train_acc, test_losses, test_acc = metrics\n","        fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n","        axs[0, 0].plot(train_losses)\n","        axs[0, 0].set_title(\"Training Loss\")\n","        axs[1, 0].plot(train_acc)\n","        axs[1, 0].set_title(\"Training Accuracy\")\n","        axs[0, 1].plot(test_losses)\n","        axs[0, 1].set_title(\"Test Loss\")\n","        axs[1, 1].plot(test_acc)\n","        axs[1, 1].set_title(\"Test Accuracy\")"],"metadata":{"id":"zLu1bv6cbKPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def printTrainTest_LossAcc(train_losses, train_acc, test_losses,test_acc):\n","  fig, axs = plt.subplots(2,2,figsize=(15,10))\n","  axs[0, 0].plot(train_losses)\n","  axs[0, 0].set_title(\"Training Loss\")\n","  axs[1, 0].plot(train_acc)\n","  axs[1, 0].set_title(\"Training Accuracy\")\n","  axs[0, 1].plot(test_losses)\n","  axs[0, 1].set_title(\"Test Loss\")\n","  axs[1, 1].plot(test_acc)\n","  axs[1, 1].set_title(\"Test Accuracy\")"],"metadata":{"id":"vWtlMRPL4rXS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_misclassified_data(model, device, test_loader):\n","    \"\"\"\n","    Function to run the model on test set and return misclassified images\n","    :param model: Network Architecture\n","    :param device: CPU/GPU\n","    :param test_loader: DataLoader for test set\n","    \"\"\"\n","    # Prepare the model for evaluation i.e. drop the dropout layer\n","    model.eval()\n","\n","    # List to store misclassified Images\n","    misclassified_data = []\n","\n","    # Reset the gradients\n","    with torch.no_grad():\n","        # Extract images, labels in a batch\n","        for data, target in test_loader:\n","\n","            # Migrate the data to the device\n","            data, target = data.to(device), target.to(device)\n","\n","            # Extract single image, label from the batch\n","            for image, label in zip(data, target):\n","\n","                # Add batch dimension to the image\n","                image = image.unsqueeze(0)\n","\n","                # Get the model prediction on the image\n","                output = model(image)\n","\n","                # Convert the output from one-hot encoding to a value\n","                pred = output.argmax(dim=1, keepdim=True)\n","\n","                # If prediction is incorrect, append the data\n","                if pred != label:\n","                    misclassified_data.append((image, label, pred))\n","    return misclassified_data"],"metadata":{"id":"pR4ZFMqS4L2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def display_gradcam_output(data: list,\n","                           classes: list[str],\n","                           inv_normalize: transforms.Normalize,\n","                           model: 'DL Model',\n","                           target_layers: list['model_layer'],\n","                           targets=None,\n","                           number_of_samples: int = 10,\n","                           transparency: float = 0.60):\n","    \"\"\"\n","    Function to visualize GradCam output on the data\n","    :param data: List[Tuple(image, label)]\n","    :param classes: Name of classes in the dataset\n","    :param inv_normalize: Mean and Standard deviation values of the dataset\n","    :param model: Model architecture\n","    :param target_layers: Layers on which GradCam should be executed\n","    :param targets: Classes to be focused on for GradCam\n","    :param number_of_samples: Number of images to print\n","    :param transparency: Weight of Normal image when mixed with activations\n","    \"\"\"\n","    # Plot configuration\n","    fig = plt.figure(figsize=(10, 10))\n","    x_count = 5\n","    y_count = 1 if number_of_samples <= 5 else math.floor(number_of_samples / x_count)\n","\n","    # Create an object for GradCam\n","    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n","\n","    # Iterate over number of specified images\n","    for i in range(number_of_samples):\n","        plt.subplot(y_count, x_count, i + 1)\n","        input_tensor = data[i][0]\n","\n","        # Get the activations of the layer for the images\n","        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n","        grayscale_cam = grayscale_cam[0, :]\n","\n","        # Get back the original image\n","        img = input_tensor.squeeze(0).to('cpu')\n","        img = inv_normalize(img)\n","        rgb_img = np.transpose(img, (1, 2, 0))\n","        rgb_img = rgb_img.numpy()\n","\n","        # Mix the activations on the original image\n","        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True, image_weight=transparency)\n","\n","        # Display the images on the plot\n","        plt.imshow(visualization)\n","        plt.title(r\"Correct: \" + classes[data[i][1].item()] + '\\n' + 'Output: ' + classes[data[i][2].item()])\n","        plt.xticks([])\n","        plt.yticks([])"],"metadata":{"id":"qlo8SKw-4fFw"},"execution_count":null,"outputs":[]}]}