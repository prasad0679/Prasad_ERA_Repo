# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pLYG7_S1hRzgoSHS1q0qMN1dpIba1X0j
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchsummary import summary

class NetArch(nn.Module):
    def __init__(self):
        super(NetArch,self).__init__()

        self.conv_block1 = nn.Sequential(
            nn.Conv2d(3,20,3,padding=1),
            nn.BatchNorm2d(20),
            nn.ReLU(),
            nn.Conv2d(20,32,3,padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Conv2d(32,64,3,stride=2,padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU())


        self.conv_block2 = nn.Sequential(
            nn.Conv2d(64,128,3,padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),

            nn.Conv2d(128,128,3,padding=1,groups=64),
            nn.Conv2d(128,64,1),
            nn.ReLU(),


            nn.Conv2d(64,32,3,stride=2,padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU())

        self.conv_block3 = nn.Sequential(
            nn.Conv2d(32,64,3,padding=1,dilation=2),
            nn.BatchNorm2d(64),
            nn.ReLU(),

            nn.Conv2d(64,32,3,padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),

            nn.Conv2d(32,32,3,stride=2,padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU())

        self.conv_block4 = nn.Sequential(
            nn.Conv2d(32,16,3,padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.Conv2d(16,10,3,padding=1),

            nn.AvgPool2d(3))

        self.fc = nn.Linear(1*1*16,10)
        self.dropout = nn.Dropout2d(0.045)
    def forward(self,x):
        x = self.conv_block1(x)
        x = self.dropout(x)
        x = self.conv_block2(x)
        x = self.dropout(x)
        x = self.conv_block3(x)
        x = self.dropout(x)
        x = self.conv_block4(x)
        x = x.view(-1,10)


        return F.log_softmax(x,dim=-1)

def return_summary(model,device, INPUT_SIZE):
    return summary(model, input_size=INPUT_SIZE)